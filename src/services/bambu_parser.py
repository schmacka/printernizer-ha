"""
Bambu G-code and 3MF file parser for extracting thumbnails and metadata.
Supports parsing Bambu Lab slicer generated files for thumbnails and print information.
"""
import re
import base64
import binascii
import zipfile
import xml.etree.ElementTree as ET
from typing import Dict, Any, Optional, List, Tuple
from pathlib import Path
from io import BytesIO
import structlog

logger = structlog.get_logger()


class BambuParser:
    """Parser for Bambu Lab G-code and 3MF files to extract thumbnails and metadata."""
    
    # G-code comment patterns for Bambu Lab files
    THUMBNAIL_PATTERN = re.compile(r'; thumbnail begin (\d+)x(\d+) (\d+)', re.MULTILINE)
    THUMBNAIL_END_PATTERN = re.compile(r'; thumbnail end', re.MULTILINE)
    
    # Metadata patterns from G-code comments
    METADATA_PATTERNS = {
        'estimated_time': re.compile(r'; estimated printing time \(normal mode\) = (.+)', re.IGNORECASE),
        'model_printing_time': re.compile(r'; model printing time[:\s]+(.+)', re.IGNORECASE),
        'layer_height': re.compile(r'; layer_height = ([\d.]+)', re.IGNORECASE),
        'first_layer_height': re.compile(r'; first_layer_height = ([\d.]+)', re.IGNORECASE),
        'infill_density': re.compile(r'; fill_density = ([\d.]+)', re.IGNORECASE),
        'support_used': re.compile(r'; support_used = (.+)', re.IGNORECASE),
        'nozzle_temperature': re.compile(r'; nozzle_temperature_initial_layer = (\d+)', re.IGNORECASE),
        'bed_temperature': re.compile(r'; bed_temperature_initial_layer = (\d+)', re.IGNORECASE),
        'total_layer_count': re.compile(r'; total layer count = (\d+)', re.IGNORECASE),
        'print_speed': re.compile(r'; outer_wall_speed = ([\d.]+)', re.IGNORECASE),
    }
    
    # Filament usage patterns (Bambu AMS specific)
    FILAMENT_PATTERNS = {
        'filament_used': re.compile(r'; filament used \[g\] = ([\d.,]+)', re.IGNORECASE),
        'filament_cost': re.compile(r'; filament cost = ([\d.]+)', re.IGNORECASE),
        'filament_type': re.compile(r'; filament_type = (.+)', re.IGNORECASE),
        'filament_ids': re.compile(r'; filament_ids = (.+)', re.IGNORECASE),
    }
    
    # Advanced metadata patterns for enhanced extraction
    ADVANCED_METADATA_PATTERNS = {
        # Physical properties
        'model_width': re.compile(r'; model_width = ([\d.]+)', re.IGNORECASE),
        'model_depth': re.compile(r'; model_depth = ([\d.]+)', re.IGNORECASE),
        'model_height': re.compile(r'; model_height = ([\d.]+)', re.IGNORECASE),
        'max_z_height': re.compile(r'; max_z_height = ([\d.]+)', re.IGNORECASE),
        
        # Print settings
        'nozzle_diameter': re.compile(r'; nozzle_diameter = ([\d.]+)', re.IGNORECASE),
        'wall_loops': re.compile(r'; wall_loops = (\d+)', re.IGNORECASE),
        'top_shell_layers': re.compile(r'; top_shell_layers = (\d+)', re.IGNORECASE),
        'bottom_shell_layers': re.compile(r'; bottom_shell_layers = (\d+)', re.IGNORECASE),
        'sparse_infill_pattern': re.compile(r'; sparse_infill_pattern = (.+)', re.IGNORECASE),
        'sparse_infill_density': re.compile(r'; sparse_infill_density = ([\d.]+)%?', re.IGNORECASE),
        
        # Advanced settings
        'overhang_speed': re.compile(r'; overhang_speed = ([\d.]+)', re.IGNORECASE),
        'bridge_speed': re.compile(r'; bridge_speed = ([\d.]+)', re.IGNORECASE),
        'support_threshold_angle': re.compile(r'; support_threshold_angle = (\d+)', re.IGNORECASE),
        'enable_support': re.compile(r'; enable_support = (.+)', re.IGNORECASE),
        
        # Compatibility
        'compatible_printers': re.compile(r'; compatible_printers = (.+)', re.IGNORECASE),
        'curr_bed_type': re.compile(r'; curr_bed_type = (.+)', re.IGNORECASE),
        
        # Slicer information
        'generator': re.compile(r'; generated by (.+)', re.IGNORECASE),
        
        # Material properties
        'filament_density': re.compile(r'; filament_density = ([\d.,]+)', re.IGNORECASE),
        'filament_diameter': re.compile(r'; filament_diameter = ([\d.,]+)', re.IGNORECASE),
        'total_filament_weight': re.compile(r'; total filament weight \[g\] : ([\d.,]+)', re.IGNORECASE),
        'total_filament_length': re.compile(r'; total filament used \[mm\] : ([\d.,]+)', re.IGNORECASE),
    }
    
    def __init__(self):
        """Initialize the Bambu parser."""
        pass
    
    async def parse_file(self, file_path: str) -> Dict[str, Any]:
        """
        Parse a Bambu G-code or 3MF file and extract thumbnails and metadata.

        Args:
            file_path: Path to the file to parse

        Returns:
            Dictionary containing parsed data with keys:
            - thumbnails: List of thumbnail data (base64, width, height)
            - metadata: Dictionary of parsed metadata
            - success: Boolean indicating if parsing was successful
            - error: Error message if parsing failed
            - needs_generation: Boolean indicating if preview rendering is needed
        """
        try:
            file_path = Path(file_path)

            if not file_path.exists():
                return {
                    'success': False,
                    'error': f"File not found: {file_path}",
                    'thumbnails': [],
                    'metadata': {},
                    'needs_generation': False
                }

            # Determine file type and parse accordingly
            if file_path.suffix.lower() == '.3mf':
                return await self._parse_3mf_file(file_path)
            elif file_path.suffix.lower() in ['.gcode', '.g']:
                return await self._parse_gcode_file(file_path)
            elif file_path.suffix.lower() == '.bgcode':
                return await self._parse_bgcode_file(file_path)
            elif file_path.suffix.lower() == '.stl':
                return await self._parse_stl_file(file_path)
            else:
                return {
                    'success': False,
                    'error': f"Unsupported file type: {file_path.suffix}",
                    'thumbnails': [],
                    'metadata': {},
                    'needs_generation': False
                }

        except Exception as e:
            logger.error("Failed to parse file", file_path=str(file_path), error=str(e))
            return {
                'success': False,
                'error': str(e),
                'thumbnails': [],
                'metadata': {},
                'needs_generation': False
            }
    
    async def _parse_gcode_file(self, file_path: Path) -> Dict[str, Any]:
        """Parse G-code file for thumbnails and metadata."""
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            # Extract thumbnails
            thumbnails = self._extract_gcode_thumbnails(content)
            
            # Extract metadata
            metadata = self._extract_gcode_metadata(content)
            
            logger.info("Successfully parsed G-code file",
                       file_path=str(file_path),
                       thumbnail_count=len(thumbnails),
                       metadata_keys=list(metadata.keys()))

            return {
                'success': True,
                'thumbnails': thumbnails,
                'metadata': metadata,
                'error': None,
                'needs_generation': len(thumbnails) == 0  # Generate if no embedded thumbnails
            }
            
        except Exception as e:
            logger.error("Failed to parse G-code file", file_path=str(file_path), error=str(e))
            return {
                'success': False,
                'error': str(e),
                'thumbnails': [],
                'metadata': {},
                'needs_generation': False
            }
    
    async def _parse_3mf_file(self, file_path: Path) -> Dict[str, Any]:
        """Parse 3MF file for thumbnails and metadata."""
        try:
            thumbnails = []
            metadata = {}
            
            with zipfile.ZipFile(file_path, 'r') as zip_file:
                # Look for thumbnail images in 3MF package
                thumbnail_files = [f for f in zip_file.namelist() 
                                 if f.startswith('Metadata/') and f.endswith('.png')]
                
                # Extract thumbnails
                for thumb_file in thumbnail_files:
                    try:
                        with zip_file.open(thumb_file) as thumb:
                            thumb_data = thumb.read()
                            thumb_base64 = base64.b64encode(thumb_data).decode('utf-8')
                            
                            # Try to get dimensions from filename or default
                            width, height = self._parse_thumbnail_dimensions(thumb_file)
                            
                            thumbnails.append({
                                'data': thumb_base64,
                                'width': width,
                                'height': height,
                                'format': 'png',
                                'source_file': thumb_file
                            })
                            
                    except Exception as e:
                        logger.warning("Failed to extract thumbnail from 3MF", 
                                     file=thumb_file, error=str(e))
                        continue
                
                # Parse 3MF model file for metadata
                try:
                    with zip_file.open('3D/3dmodel.model') as model_file:
                        model_content = model_file.read().decode('utf-8')
                        metadata.update(self._extract_3mf_metadata(model_content))
                except Exception as e:
                    logger.warning("Could not parse 3MF model metadata", error=str(e))
                
                # Look for other metadata files
                metadata_files = [f for f in zip_file.namelist() 
                                if f.startswith('Metadata/') and f.endswith('.xml')]
                
                for meta_file in metadata_files:
                    try:
                        with zip_file.open(meta_file) as meta:
                            meta_content = meta.read().decode('utf-8')
                            metadata.update(self._extract_3mf_metadata(meta_content))
                    except Exception as e:
                        logger.warning("Failed to parse 3MF metadata file", 
                                     file=meta_file, error=str(e))
                        continue
            
            logger.info("Successfully parsed 3MF file",
                       file_path=str(file_path),
                       thumbnail_count=len(thumbnails),
                       metadata_keys=list(metadata.keys()))

            return {
                'success': True,
                'thumbnails': thumbnails,
                'metadata': metadata,
                'error': None,
                'needs_generation': len(thumbnails) == 0  # Generate if no embedded thumbnails
            }
            
        except Exception as e:
            logger.error("Failed to parse 3MF file", file_path=str(file_path), error=str(e))
            return {
                'success': False,
                'error': str(e),
                'thumbnails': [],
                'metadata': {},
                'needs_generation': False
            }
    
    def _extract_gcode_thumbnails(self, content: str) -> List[Dict[str, Any]]:
        """Extract thumbnails from G-code comments."""
        thumbnails = []
        
        # Find all thumbnail sections
        thumbnail_matches = list(self.THUMBNAIL_PATTERN.finditer(content))
        thumbnail_end_matches = list(self.THUMBNAIL_END_PATTERN.finditer(content))
        
        if len(thumbnail_matches) != len(thumbnail_end_matches):
            logger.warning("Mismatched thumbnail begin/end markers", 
                          begin_count=len(thumbnail_matches),
                          end_count=len(thumbnail_end_matches))
            return thumbnails
        
        for i, begin_match in enumerate(thumbnail_matches):
            try:
                width = int(begin_match.group(1))
                height = int(begin_match.group(2))
                data_size = int(begin_match.group(3))
                
                if i < len(thumbnail_end_matches):
                    end_match = thumbnail_end_matches[i]
                    
                    # Extract the base64 data between begin and end
                    start_pos = begin_match.end()
                    end_pos = end_match.start()
                    thumbnail_section = content[start_pos:end_pos]
                    
                    # Clean up the data - remove comment markers and whitespace
                    thumbnail_data = ''
                    for line in thumbnail_section.split('\n'):
                        line = line.strip()
                        if line.startswith(';') and len(line) > 2:
                            # Remove comment marker and spaces
                            clean_line = line[1:].strip()
                            thumbnail_data += clean_line
                    
                    # Validate base64 data
                    if thumbnail_data and self._is_valid_base64(thumbnail_data):
                        thumbnails.append({
                            'data': thumbnail_data,
                            'width': width,
                            'height': height,
                            'format': 'png',
                            'data_size': data_size,
                            'source': 'gcode_comment'
                        })
                        
                        logger.debug("Extracted thumbnail from G-code", 
                                   width=width, height=height, data_size=data_size)
                    else:
                        logger.warning("Invalid base64 thumbnail data found")
                        
            except (ValueError, IndexError) as e:
                logger.warning("Failed to parse thumbnail", error=str(e))
                continue
        
        return thumbnails
    
    def _extract_gcode_metadata(self, content: str) -> Dict[str, Any]:
        """Extract metadata from G-code comments."""
        metadata = {}
        
        # Extract standard metadata
        for key, pattern in self.METADATA_PATTERNS.items():
            match = pattern.search(content)
            if match:
                value = match.group(1).strip()
                
                # Convert to appropriate type
                if key in ['layer_height', 'first_layer_height', 'infill_density', 'print_speed']:
                    try:
                        metadata[key] = float(value)
                    except ValueError:
                        metadata[key] = value
                elif key in ['nozzle_temperature', 'bed_temperature', 'total_layer_count']:
                    try:
                        metadata[key] = int(value)
                    except ValueError:
                        metadata[key] = value
                elif key == 'estimated_time' or key == 'model_printing_time':
                    metadata['estimated_time'] = self._parse_time_duration(value)
                elif key == 'support_used':
                    metadata[key] = value.lower() in ['true', '1', 'yes']
                else:
                    metadata[key] = value
        
        # Extract filament information
        for key, pattern in self.FILAMENT_PATTERNS.items():
            match = pattern.search(content)
            if match:
                value = match.group(1).strip()
                
                if key == 'filament_used':
                    # Parse comma-separated list of filament usage per extruder
                    try:
                        filament_amounts = [float(x.strip()) for x in value.split(',')]
                        metadata['filament_used_grams'] = filament_amounts
                        metadata['total_filament_used'] = sum(filament_amounts)
                    except ValueError:
                        metadata[key] = value
                elif key == 'filament_cost':
                    try:
                        metadata[key] = float(value)
                    except ValueError:
                        metadata[key] = value
                elif key == 'filament_ids':
                    # Split AMS slot IDs
                    metadata['filament_ams_slots'] = [x.strip() for x in value.split(',')]
                else:
                    metadata[key] = value
        
        # Extract advanced metadata patterns
        metadata.update(self._extract_advanced_metadata(content))
        
        # Calculate derived metrics
        metadata.update(self._calculate_derived_metrics(metadata))
        
        return metadata
    
    def _extract_advanced_metadata(self, content: str) -> Dict[str, Any]:
        """Extract advanced metadata from G-code content."""
        advanced_metadata = {}
        
        for key, pattern in self.ADVANCED_METADATA_PATTERNS.items():
            match = pattern.search(content)
            if match:
                value = match.group(1).strip()
                advanced_metadata[key] = self._convert_metadata_value(key, value)
        
        return advanced_metadata
    
    def _convert_metadata_value(self, key: str, value: str) -> Any:
        """Convert string values to appropriate types based on key."""
        # Numeric fields (float)
        if key in ['model_width', 'model_depth', 'model_height', 'max_z_height',
                   'nozzle_diameter', 'overhang_speed', 'bridge_speed', 
                   'sparse_infill_density']:
            try:
                return float(value)
            except ValueError:
                return value
        
        # Integer fields
        elif key in ['wall_loops', 'top_shell_layers', 'bottom_shell_layers', 
                     'support_threshold_angle']:
            try:
                return int(value)
            except ValueError:
                return value
        
        # Comma-separated numeric lists (multi-material)
        elif key in ['filament_density', 'filament_diameter', 'total_filament_weight',
                     'total_filament_length']:
            try:
                # Handle comma-separated values
                if ',' in value:
                    return [float(x.strip()) for x in value.split(',')]
                else:
                    return float(value)
            except ValueError:
                return value
        
        # Boolean fields
        elif key in ['enable_support']:
            return value.lower() in ['true', '1', 'yes']
        
        # List fields (printers, etc.)
        elif key == 'compatible_printers':
            # Parse printer list - handle both comma and semicolon separators
            printers = []
            for sep in [',', ';']:
                if sep in value:
                    printers = [p.strip().strip('"') for p in value.split(sep)]
                    break
            if not printers:
                printers = [value.strip().strip('"')]
            return printers
        
        # String fields
        else:
            return value
    
    def _calculate_derived_metrics(self, metadata: Dict[str, Any]) -> Dict[str, Any]:
        """Calculate derived metrics from extracted metadata."""
        derived = {}
        
        # Calculate wall thickness from wall loops and nozzle diameter
        if 'wall_loops' in metadata and 'nozzle_diameter' in metadata:
            try:
                wall_loops = metadata['wall_loops']
                nozzle_diameter = metadata['nozzle_diameter']
                derived['wall_thickness'] = round(wall_loops * nozzle_diameter, 2)
            except (TypeError, ValueError):
                pass
        
        # Calculate total filament weight from multiple sources
        if 'total_filament_weight' in metadata:
            weight = metadata['total_filament_weight']
            if isinstance(weight, list):
                derived['total_filament_weight_sum'] = round(sum(weight), 2)
            elif isinstance(weight, (int, float)):
                derived['total_filament_weight_sum'] = round(float(weight), 2)
        
        # Calculate total filament length
        if 'total_filament_length' in metadata:
            length = metadata['total_filament_length']
            if isinstance(length, list):
                # Convert mm to meters
                derived['filament_length_meters'] = round(sum(length) / 1000, 2)
            elif isinstance(length, (int, float)):
                derived['filament_length_meters'] = round(float(length) / 1000, 2)
        
        # Use max_z_height as model_height if not available
        if 'max_z_height' in metadata and 'model_height' not in metadata:
            derived['model_height'] = metadata['max_z_height']
        
        # Calculate complexity score (1-10 scale)
        derived['complexity_score'] = self._calculate_complexity_score(metadata)
        
        # Estimate difficulty level
        derived['difficulty_level'] = self._calculate_difficulty_level(metadata)
        
        # Calculate material cost estimate (if filament weight available)
        if 'total_filament_weight_sum' in derived or 'total_filament_used' in metadata:
            weight = derived.get('total_filament_weight_sum') or metadata.get('total_filament_used', 0)
            # Default cost: €25/kg for PLA
            material_cost_per_kg = 25.0
            derived['material_cost_estimate'] = round((weight / 1000) * material_cost_per_kg, 2)
        
        # Calculate energy cost estimate (if print time available)
        if 'estimated_time' in metadata or 'model printing time' in metadata:
            # Get print time in seconds
            print_time_seconds = metadata.get('estimated_time', 0)
            
            # If we don't have estimated_time, it might be a string in the metadata
            if not print_time_seconds and 'model printing time' in metadata:
                # This might have been parsed as a string, we don't have seconds yet
                # Skip energy cost if we can't get the time
                pass
            else:
                # Estimate power consumption: ~200W average for heated bed + hotend
                power_watts = 200
                energy_kwh = (power_watts * print_time_seconds) / (1000 * 3600)
                # €0.30 per kWh
                energy_cost_per_kwh = 0.30
                derived['energy_cost_estimate'] = round(energy_kwh * energy_cost_per_kwh, 2)
        
        # Calculate total cost
        if 'material_cost_estimate' in derived and 'energy_cost_estimate' in derived:
            derived['total_cost_estimate'] = round(
                derived['material_cost_estimate'] + derived['energy_cost_estimate'], 2
            )
        
        return derived
    
    def _calculate_complexity_score(self, metadata: Dict[str, Any]) -> int:
        """Calculate print complexity score (1-10 scale)."""
        score = 5  # Base score
        
        # Layer height factor (finer = more complex)
        layer_height = metadata.get('layer_height', 0.2)
        if layer_height:
            if layer_height <= 0.1:
                score += 2  # Very fine layers
            elif layer_height <= 0.15:
                score += 1  # Fine layers
            elif layer_height >= 0.3:
                score -= 1  # Coarse layers (easier)
        
        # Support usage increases complexity
        if metadata.get('support_used') or metadata.get('enable_support'):
            score += 1
        
        # High infill increases complexity
        infill_density = metadata.get('infill_density', 20) or metadata.get('sparse_infill_density', 20)
        if infill_density:
            if infill_density > 80:
                score += 1
        
        # Complex infill patterns
        infill_pattern = metadata.get('infill_pattern') or metadata.get('sparse_infill_pattern', '')
        if infill_pattern:
            complex_patterns = ['gyroid', 'voronoi', 'lightning', 'adaptive']
            if any(pattern in str(infill_pattern).lower() for pattern in complex_patterns):
                score += 1
        
        # Multi-material printing is more complex
        filament_weights = metadata.get('filament_used_grams', [])
        if isinstance(filament_weights, list) and len(filament_weights) > 1:
            # Check if multiple materials actually used (non-zero weights)
            used_materials = sum(1 for w in filament_weights if w > 0)
            if used_materials > 1:
                score += used_materials - 1
        
        # Large models (more layers) are more complex
        layer_count = metadata.get('total_layer_count', 0)
        if layer_count:
            if layer_count > 500:
                score += 1
            elif layer_count > 1000:
                score += 2
        
        # Clamp score to 1-10 range
        return max(1, min(10, score))
    
    def _calculate_difficulty_level(self, metadata: Dict[str, Any]) -> str:
        """Calculate difficulty level based on complexity."""
        complexity = self._calculate_complexity_score(metadata)
        
        if complexity <= 3:
            return 'Beginner'
        elif complexity <= 6:
            return 'Intermediate'
        elif complexity <= 8:
            return 'Advanced'
        else:
            return 'Expert'
    
    def _extract_3mf_metadata(self, xml_content: str) -> Dict[str, Any]:
        """Extract metadata from 3MF XML files."""
        metadata = {}

        try:
            root = ET.fromstring(xml_content)

            # Look for metadata elements
            for elem in root.iter():
                if 'metadata' in elem.tag.lower():
                    name = elem.get('name', '')
                    value = elem.text or elem.get('value', '')

                    if name and value:
                        # Convert known numeric fields
                        if name.lower() in ['layer_height', 'layer_count', 'print_time',
                                          'nozzle_temperature', 'bed_temperature']:
                            try:
                                if '.' in value:
                                    metadata[name.lower()] = float(value)
                                else:
                                    metadata[name.lower()] = int(value)
                            except ValueError:
                                metadata[name.lower()] = value
                        else:
                            metadata[name.lower()] = value

            # Extract model dimensions from vertices (bounding box calculation)
            # 3MF files contain vertices in the <mesh> elements
            try:
                dimensions = self._extract_3mf_dimensions(root)
                if dimensions:
                    metadata.update(dimensions)
            except Exception as e:
                logger.debug("Could not extract dimensions from 3MF model", error=str(e))

        except ET.ParseError as e:
            logger.warning("Failed to parse 3MF XML metadata", error=str(e))

        return metadata

    def _extract_3mf_dimensions(self, root_element) -> Dict[str, Any]:
        """Extract physical dimensions from 3MF model by calculating bounding box."""
        dimensions = {}

        # Find all vertices in the model
        # 3MF uses namespace, need to handle it
        namespaces = {
            '3mf': 'http://schemas.microsoft.com/3dmanufacturing/core/2015/02',
            'model': 'http://schemas.microsoft.com/3dmanufacturing/core/2015/02'
        }

        # Try to find vertices without namespace first (some slicers don't use it)
        vertices = []

        # Search for <vertex> elements
        for vertex in root_element.findall('.//*'):
            if vertex.tag.endswith('vertex'):
                try:
                    x = float(vertex.get('x', 0))
                    y = float(vertex.get('y', 0))
                    z = float(vertex.get('z', 0))
                    vertices.append((x, y, z))
                except (ValueError, TypeError):
                    continue

        # Calculate bounding box if we found vertices
        if vertices:
            min_x = min(v[0] for v in vertices)
            max_x = max(v[0] for v in vertices)
            min_y = min(v[1] for v in vertices)
            max_y = max(v[1] for v in vertices)
            min_z = min(v[2] for v in vertices)
            max_z = max(v[2] for v in vertices)

            # Calculate dimensions in mm
            dimensions['model_width'] = round(max_x - min_x, 2)
            dimensions['model_depth'] = round(max_y - min_y, 2)
            dimensions['model_height'] = round(max_z - min_z, 2)

            # Calculate volume (simple bounding box volume, not actual mesh volume)
            volume_mm3 = (max_x - min_x) * (max_y - min_y) * (max_z - min_z)
            dimensions['model_volume'] = round(volume_mm3 / 1000, 2)  # Convert to cm³

            # Calculate approximate surface area (bounding box surface area)
            width = max_x - min_x
            depth = max_y - min_y
            height = max_z - min_z
            surface_area_mm2 = 2 * (width * depth + width * height + depth * height)
            dimensions['surface_area'] = round(surface_area_mm2 / 100, 2)  # Convert to cm²

            logger.debug("Extracted 3MF dimensions",
                        width=dimensions['model_width'],
                        depth=dimensions['model_depth'],
                        height=dimensions['model_height'],
                        vertices=len(vertices))

        return dimensions
    
    async def _parse_bgcode_file(self, file_path: Path) -> Dict[str, Any]:
        """Parse Binary G-code file for thumbnails and metadata.
        
        BGCode is a binary format that contains structured blocks.
        For now, we'll implement basic parsing to extract embedded thumbnails.
        """
        try:
            thumbnails = []
            metadata = {}
            
            with open(file_path, 'rb') as f:
                # Read BGCode file header
                # BGCode files start with specific magic bytes
                magic = f.read(4)
                if magic != b'BGD\x00':  # BGCode magic bytes
                    logger.warning("File doesn't appear to be valid BGCode format", 
                                 magic=magic.hex())
                    return {
                        'success': False,
                        'error': f"Invalid BGCode magic bytes: {magic.hex()}",
                        'thumbnails': [],
                        'metadata': {}
                    }
                
                # For now, we'll attempt to find embedded PNG thumbnails
                # by scanning for PNG headers in the binary data
                f.seek(0)  # Reset to beginning
                content = f.read()
                
                # Look for PNG signatures in the binary data
                png_start = b'\x89PNG\r\n\x1a\n'
                png_positions = []
                start = 0
                while True:
                    pos = content.find(png_start, start)
                    if pos == -1:
                        break
                    png_positions.append(pos)
                    start = pos + 1
                
                # Extract PNG thumbnails
                for i, png_pos in enumerate(png_positions):
                    try:
                        # Find the end of this PNG by looking for the next PNG or end of file
                        if i + 1 < len(png_positions):
                            end_pos = png_positions[i + 1]
                        else:
                            # Look for PNG end marker (IEND chunk)
                            iend_marker = b'IEND\xaeB`\x82'
                            end_search = content.find(iend_marker, png_pos)
                            if end_search != -1:
                                end_pos = end_search + len(iend_marker)
                            else:
                                # If we can't find IEND, take a reasonable chunk
                                end_pos = min(png_pos + 100000, len(content))  # Max 100KB per thumbnail
                        
                        png_data = content[png_pos:end_pos]
                        
                        # Validate this is actually a complete PNG
                        if len(png_data) < 100:  # Too small to be a real thumbnail
                            continue
                            
                        # Convert to base64
                        thumbnail_base64 = base64.b64encode(png_data).decode('utf-8')
                        
                        # Try to extract dimensions from PNG header
                        width, height = self._extract_png_dimensions(png_data)
                        
                        thumbnails.append({
                            'data': thumbnail_base64,
                            'width': width,
                            'height': height,
                            'format': 'PNG'
                        })
                        
                        logger.debug(f"Extracted thumbnail {i+1} from BGCode", 
                                   width=width, height=height, size_bytes=len(png_data))
                        
                    except Exception as e:
                        logger.warning(f"Failed to extract thumbnail {i+1} from BGCode", 
                                     error=str(e))
                        continue
                
                # Basic metadata extraction - try to find text blocks
                # BGCode may contain metadata in text blocks
                metadata = {
                    'file_size': len(content),
                    'format': 'bgcode',
                    'thumbnails_found': len(thumbnails)
                }
                
            logger.info("Successfully parsed BGCode file",
                       file_path=str(file_path),
                       thumbnail_count=len(thumbnails),
                       metadata_keys=list(metadata.keys()))

            return {
                'success': True,
                'thumbnails': thumbnails,
                'metadata': metadata,
                'error': None,
                'needs_generation': len(thumbnails) == 0  # Generate if no embedded thumbnails
            }
            
        except Exception as e:
            logger.error("Failed to parse BGCode file", file_path=str(file_path), error=str(e))
            return {
                'success': False,
                'error': str(e),
                'thumbnails': [],
                'metadata': {},
                'needs_generation': False
            }

    async def _parse_stl_file(self, file_path: Path) -> Dict[str, Any]:
        """
        Parse STL file - STL files never have embedded thumbnails.
        Returns success but marks that generation is needed.

        Args:
            file_path: Path to STL file

        Returns:
            Parse result indicating generation is needed
        """
        try:
            # STL files don't contain embedded thumbnails or metadata
            # We can extract basic file info though
            file_size = file_path.stat().st_size

            metadata = {
                'file_size': file_size,
                'file_type': 'stl'
            }

            logger.info("STL file detected - will require preview generation",
                       file_path=str(file_path),
                       file_size=file_size)

            return {
                'success': True,
                'thumbnails': [],
                'metadata': metadata,
                'error': None,
                'needs_generation': True  # STL always needs generation
            }

        except Exception as e:
            logger.error("Failed to parse STL file", file_path=str(file_path), error=str(e))
            return {
                'success': False,
                'error': str(e),
                'thumbnails': [],
                'metadata': {},
                'needs_generation': False
            }

    def _extract_png_dimensions(self, png_data: bytes) -> Tuple[int, int]:
        """Extract width and height from PNG header."""
        try:
            # PNG dimensions are in bytes 16-23 (big endian)
            if len(png_data) >= 24 and png_data[:8] == b'\x89PNG\r\n\x1a\n':
                width = int.from_bytes(png_data[16:20], 'big')
                height = int.from_bytes(png_data[20:24], 'big')
                return width, height
        except (ValueError, IndexError, OverflowError) as e:
            logger.debug("Could not parse PNG dimensions from header",
                        data_length=len(png_data), error=str(e))
        return 200, 200  # Default fallback dimensions

    def _parse_thumbnail_dimensions(self, filename: str) -> Tuple[int, int]:
        """Parse thumbnail dimensions from filename or return defaults."""
        # Try to extract dimensions from filename (e.g., thumbnail_200x200.png)
        dimension_match = re.search(r'(\d+)x(\d+)', filename)
        if dimension_match:
            return int(dimension_match.group(1)), int(dimension_match.group(2))
        
        # Default dimensions for 3MF thumbnails
        return 200, 200
    
    def _parse_time_duration(self, time_str: str) -> int:
        """Parse time duration string to seconds."""
        try:
            # Handle various time formats like "1h 30m 45s", "90m", "3600s", etc.
            time_str = time_str.lower().strip()
            total_seconds = 0
            
            # Extract hours
            hour_match = re.search(r'(\d+)h', time_str)
            if hour_match:
                total_seconds += int(hour_match.group(1)) * 3600
            
            # Extract minutes
            min_match = re.search(r'(\d+)m', time_str)
            if min_match:
                total_seconds += int(min_match.group(1)) * 60
            
            # Extract seconds
            sec_match = re.search(r'(\d+)s', time_str)
            if sec_match:
                total_seconds += int(sec_match.group(1))
            
            # If no time units found, assume it's just minutes
            if total_seconds == 0:
                try:
                    total_seconds = int(float(time_str)) * 60
                except ValueError:
                    total_seconds = 0
            
            return total_seconds
            
        except Exception as e:
            logger.warning("Failed to parse time duration", time_str=time_str, error=str(e))
            return 0
    
    def _is_valid_base64(self, s: str) -> bool:
        """Check if string is valid base64."""
        try:
            # Check if string length is multiple of 4 (after padding)
            if len(s) % 4 != 0:
                s += '=' * (4 - len(s) % 4)

            base64.b64decode(s, validate=True)
            return True
        except (ValueError, TypeError, binascii.Error):
            # Not valid base64
            return False
    
    def get_largest_thumbnail(self, thumbnails: List[Dict[str, Any]]) -> Optional[Dict[str, Any]]:
        """Get the largest thumbnail from a list of thumbnails."""
        if not thumbnails:
            return None
        
        # Find thumbnail with largest resolution
        largest = max(thumbnails, key=lambda t: t.get('width', 0) * t.get('height', 0))
        return largest
    
    def get_thumbnail_by_size(self, thumbnails: List[Dict[str, Any]], 
                             preferred_size: Tuple[int, int] = (200, 200)) -> Optional[Dict[str, Any]]:
        """Get thumbnail closest to preferred size."""
        if not thumbnails:
            return None
        
        preferred_width, preferred_height = preferred_size
        preferred_area = preferred_width * preferred_height
        
        # Find thumbnail with area closest to preferred
        closest = min(thumbnails, 
                     key=lambda t: abs((t.get('width', 0) * t.get('height', 0)) - preferred_area))
        
        return closest